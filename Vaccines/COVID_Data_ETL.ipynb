{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL - COVID State Vaccination Data\n",
    "This project collects, cleans and consolidates COVID data into a Postgres Database \n",
    "- **Vaccination Data**: I was unable to find consolidated vaccine data on the CDC websites that would let me download daily vaccination counts by State. So I used the \"Our World in Data\" site ( https://ourworldindata.org/us-states-vaccinations ) and downloaded serveral different files:\n",
    "    - us-covid-number-fully-vaccinated-in-US.csv\n",
    "    - us-covid-share-fully-vaccinated.csv\n",
    "    - us-daily-covid-vaccine-doses-administered-by-state.csv\n",
    "    - us-daily-covid-vaccine-doses-per-million.csv\n",
    "- **COVID Cases and Deaths**: I downloaded this from CDC's COVID Data Tracker at https://data.cdc.gov/Case-Surveillance/United-States-COVID-19-Cases-and-Deaths-by-State-o/9mfq-cb36 \n",
    "    - United_States_COVID_19_Cases_and_Deaths_by_State_over_Time.csv\n",
    "\n",
    "The various steps are detailed below:\n",
    "1. [Extract and Transform National and State level Vaccination Data](#Extract-and-Transform-National-and-State-level-Vaccination-Data)\n",
    "2. [Extract and Transform COVID Case Data](#Extract-and-Transform-COVID-Case-Data)\n",
    "3. [Extract and Transform COVID Death Data](#Extract-and-Transform-COVID-Death-Data)\n",
    "2. [Load all data to the COVID PostgreSQL Database](#Load-Final-Data-to-PostgreSQL-Database)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "# Import psycopg2 - the DB API 2.0 compliant PostgreSQL driver for Python\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract and Transform National and State level Vaccination Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Files to Load\n",
    "number_fully_vaccinated_to_load = \"Resources/us-covid-number-fully-vaccinated-in-US.csv\"\n",
    "share_fully_vaccinated_to_load = \"Resources/us-covid-share-fully-vaccinated.csv\"\n",
    "number_doses_administered_to_load = \"Resources/us-daily-covid-vaccine-doses-administered-by-state.csv\"\n",
    "number_doses_per_million_to_load = \"Resources/us-daily-covid-vaccine-doses-per-million.csv\"\n",
    "\n",
    "# Read Vaccine data files and store into Pandas DataFrames\n",
    "nbr_fully_vaccinated_df = pd.read_csv(number_fully_vaccinated_to_load)\n",
    "shr_fully_vaccinated_df = pd.read_csv(share_fully_vaccinated_to_load)\n",
    "nbr_doses_administered_df = pd.read_csv(number_doses_administered_to_load)\n",
    "nbr_doses_per_million_df = pd.read_csv(number_doses_per_million_to_load)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty columns before merging\n",
    "nbr_fully_vaccinated_df = nbr_fully_vaccinated_df.drop(columns=['Code'])\n",
    "shr_fully_vaccinated_df = shr_fully_vaccinated_df.drop(columns=['Code'])\n",
    "nbr_doses_administered_df = nbr_doses_administered_df.drop(columns=['Code'])\n",
    "nbr_doses_per_million_df = nbr_doses_per_million_df.drop(columns=['Code'])\n",
    "\n",
    "# Combine the data into a single dataset dropping the empty columns \n",
    "df1 = pd.merge(nbr_fully_vaccinated_df, shr_fully_vaccinated_df, how=\"left\", on=[\"Entity\",\"Date\"])\n",
    "df2 = pd.merge(df1,nbr_doses_administered_df, how=\"left\", on=[\"Entity\",\"Date\"])\n",
    "df3 = pd.merge(df2, nbr_doses_per_million_df, how=\"left\", on=[\"Entity\",\"Date\"])\n",
    "# df3.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the merged file: \n",
    "# Remove duplicate data that is listed under Federal Agencies (in addition to containing duplicates, it also contains\n",
    "# many NaNs): Bureau of Prisons, Dept of Defense, Indian Health Svc, Long Term Care, Veterans Health\n",
    "vaccinations_df = df3.loc[(df3[\"Entity\"] != \"Bureau of Prisons\") &\n",
    "                          (df3[\"Entity\"] != \"Dept of Defense\") &\n",
    "                          (df3[\"Entity\"] != \"Indian Health Svc\") &\n",
    "                          (df3[\"Entity\"] != \"Long Term Care\") &\n",
    "                          (df3[\"Entity\"] != \"Veterans Health\"), :].copy()\n",
    "\n",
    "# Replace remaining NaN values with zeros - these primarily occurred on the first day of data collection for some states.\n",
    "vaccinations_df.fillna(value=0, inplace=True)\n",
    "\n",
    "# Change the columns back to integers (fillna added an unnecessary decimal position)\n",
    "vaccinations_df['daily_vaccinations'] = vaccinations_df['daily_vaccinations'].astype(int) \n",
    "vaccinations_df['daily_vaccinations_per_million'] = vaccinations_df['daily_vaccinations_per_million'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaccinations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restructure the data before finalizing it\n",
    "# Change column name from Entity to State to better reflect the content of the final, cleaned up dataframe. \n",
    "vaccinations_df.rename(columns={'Entity':'state_name', 'Date':'date_administered' }, \n",
    "                 inplace=True)\n",
    "\n",
    "# Remove the rows of national (state_name =\"US\") data into its own csv for ease of creating the 2 tables US_vaccinations\n",
    "# and State_vaccinations.\n",
    "# Important note: the national and state numbers aren't always the same, because of the way that the different\n",
    "# jurisdictions report their data and how the CDC cross-checks and totals it up so I am preserving that difference\n",
    "# by creating two separate tables\n",
    "US_vaccinations_df = vaccinations_df.loc[(vaccinations_df[\"state_name\"] == \"United States\"), :].copy()\n",
    "US_vaccinations_df = US_vaccinations_df.drop(columns=['state_name'])\n",
    "US_vaccinations_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# US_vaccinations_df = US_vaccinations_df.set_index('Date')\n",
    "\n",
    "state_vaccinations_df = vaccinations_df.loc[(vaccinations_df[\"state_name\"] != \"United States\"), :].copy()\n",
    "state_vaccinations_df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the merged/cleaned up files to new csv files for backup purposes \n",
    "US_vaccinations_df.to_csv(r\"Resources\\US_vaccinations.csv\", index = False, encoding=\"utf-8\")\n",
    "state_vaccinations_df.to_csv(r\"Resources\\State_Vaccinations.csv\", index = False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract and Transform COVID Case and Death Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files to Load\n",
    "cases_and_deaths_to_load = \"Resources/United_States_COVID-19_Cases_and_Deaths_by_State_over_Time.csv\"\n",
    "state_xref_to_load = \"Resources/State-XRef.csv\"\n",
    "\n",
    "# Read COVID cases & deaths data file and store into Pandas DataFrame\n",
    "raw_cases_deaths_df = pd.read_csv(cases_and_deaths_to_load)\n",
    "\n",
    "# Read State cross-reference data\n",
    "state_xref_df = pd.read_csv(state_xref_to_load)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cases_deaths_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add the state_name to the cases&deaths dataframe so that we will be able to join COVID cases and deaths \n",
    "# with vaccinations when querying the DB. \n",
    "df1 = pd.merge(raw_cases_deaths_df, state_xref_df, how=\"left\", on=[\"state\"])\n",
    "\n",
    "# Remove unnecessary columns\n",
    "raw_cases_deaths_df = df1.drop(columns=['conf_cases','prob_cases','pnew_case',\n",
    "                                                        'conf_death','prob_death','pnew_death',\n",
    "                                                       'created_at','consent_cases','consent_deaths','state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_date</th>\n",
       "      <th>tot_cases</th>\n",
       "      <th>new_case</th>\n",
       "      <th>tot_death</th>\n",
       "      <th>new_death</th>\n",
       "      <th>state_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/22/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Oklahoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/22/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/22/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Arkansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/22/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Utah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/22/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>New Mexico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  submission_date  tot_cases  new_case  tot_death  new_death  state_name\n",
       "0       1/22/2020          0         0          0          0    Oklahoma\n",
       "1       1/22/2020          0         0          0          0      Alaska\n",
       "2       1/22/2020          0         0          0          0    Arkansas\n",
       "3       1/22/2020          0         0          0          0        Utah\n",
       "4       1/22/2020          0         0          0          0  New Mexico"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_cases_deaths_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Add the NYC totals to the NY totals and remove the NYC rows - CDC continued to track theses separately\n",
    "# since the US pandemic really ramped up in a big way in NYC at the beginning\n",
    "# Where the submission_date is the same, add the NCY values to the values in the NY columns\n",
    "# NY number = NY number + NYC number where submission_date = submission_date\n",
    "# Pull out the NY rows and the NYC rows into separate DFs for merging and totaling \n",
    "NY_cases_deaths_df = raw_cases_deaths_df.loc[(raw_cases_deaths_df[\"state_name\"] == \"New York\"), :].copy()\n",
    "NY_cases_deaths_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "NYC_cases_deaths_df = raw_cases_deaths_df.loc[(raw_cases_deaths_df[\"state_name\"] == \"New York City\"), :].copy()\n",
    "NYC_cases_deaths_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "other_states_df = raw_cases_deaths_df.loc[(raw_cases_deaths_df[\"state_name\"] != \"New York City\") &\n",
    "                                          (raw_cases_deaths_df[\"state_name\"] != \"New York\"), :].copy()\n",
    "other_states_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Merge the NY & NYC data\n",
    "merged_df = pd.merge(NY_cases_deaths_df, NYC_cases_deaths_df, how=\"left\", on=[\"submission_date\"])\n",
    "\n",
    "# Add the NY & NYC totals together and create a new DF with the daily totals aggregated\n",
    "submission_date = merged_df['submission_date']\n",
    "tot_cases = merged_df['tot_cases_x'] + merged_df['tot_cases_y']\n",
    "new_case = merged_df['new_case_x'] + merged_df['new_case_y']\n",
    "tot_death = merged_df['tot_death_x'] + merged_df['tot_death_y']\n",
    "new_death = merged_df['new_death_x'] + merged_df['new_death_y']\n",
    "merged_ny_df = pd.DataFrame({'submission_date': submission_date,\n",
    "                                     'tot_cases': tot_cases,\n",
    "                                     'new_case': new_case,\n",
    "                                     'tot_death': tot_death,\n",
    "                                     'new_death': new_death,\n",
    "                                     'state_name':'New York'\n",
    "                                    })\n",
    "\n",
    "# Add the new single combined NY/NYC rows back together with the rows from the other states\n",
    "state_cases_deaths = pd.concat([merged_ny_df, other_states_df])\n",
    "\n",
    "# Change column name from Entity to State to better reflect the content of the final, cleaned up dataframe. \n",
    "state_cases_deaths.rename(columns={'new_case':'new_cases', 'tot_death':'tot_deaths','new_death':'new_deaths' }, \n",
    "                 inplace=True)\n",
    "\n",
    "# Write the merged/cleaned up file to a new csv file for backup purposes \n",
    "state_cases_deaths.to_csv(r\"Resources\\state_cases_deaths.csv\", index = False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                Type         Data/Info\n",
      "----------------------------------------------\n",
      "NYC_cases_deaths_df     DataFrame        submission_date  tot_<...>n\\n[416 rows x 6 columns]\n",
      "NY_cases_deaths_df      DataFrame        submission_date  tot_<...>n\\n[416 rows x 6 columns]\n",
      "df1                     DataFrame          submission_date sta<...>[24960 rows x 16 columns]\n",
      "merged_df               DataFrame        submission_date  tot_<...>\\n[416 rows x 11 columns]\n",
      "merged_ny_df            DataFrame        submission_date  tot_<...>n\\n[416 rows x 6 columns]\n",
      "other_states_df         DataFrame          submission_date  to<...>n[24128 rows x 6 columns]\n",
      "raw_cases_deaths_df     DataFrame          submission_date  to<...>n[24960 rows x 6 columns]\n",
      "state_cases_deaths_df   DataFrame          submission_date  to<...>n[24544 rows x 6 columns]\n",
      "state_xref_df           DataFrame                            s<...>      New York City   NYC\n"
     ]
    }
   ],
   "source": [
    "%whos DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Final Data to PostgreSQL Database "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Final Data to PostgreSQL Database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = \"postgres:password@localhost:5432/COVID\"\n",
    "engine = create_engine(f'postgresql://{connection_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm tables\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_vaccinations_df.to_sql(name='us_vaccinations', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query('select * from us_vaccinations', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_vaccinations_df.to_sql(name='state_vaccinations', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('select * from state_vaccinations', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nteract": {
   "version": "0.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
